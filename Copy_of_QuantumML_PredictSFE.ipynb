{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e5_3W3Geo7K"
   },
   "source": [
    "# Classical ML\n",
    "\n",
    "> singularity exec --overlay /scratch/lw3266/my_env/overlay-15GB-500K.ext3:rw /scratch/work/public/singularity/cuda12.3.2-cudnn9.0.0-ubuntu-22.04.4.sif /bin/bash\n",
    "\n",
    "> source /ext3/env.sh\r\n",
    "\n",
    "Pip install any additional modules needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e5_3W3Geo7K"
   },
   "source": [
    "### Setting up\n",
    "Import the modules we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zsE7lQ_eo7L"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "x43ilLZBeo7O",
    "outputId": "1688a219-bf9e-40b8-c176-9861fbf47157"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"qml_training-validation-data.csv\", index_col = 0)\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HVTijzXTnXt"
   },
   "source": [
    "### Linear Model Training\n",
    "We first divide the dataset into test and train, with a ratio of 80 to 20.\n",
    "\n",
    "Then the linear model will be trained using the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "1jRrJv7veo7P",
    "outputId": "fab74c8a-f8ba-4d2d-e2dc-c8d90f217d6c"
   },
   "outputs": [],
   "source": [
    "y = df['SFE/mJm^-3'].values\n",
    "X = df[['el_neg', 'B/GPa', 'Volume/A^3']].values\n",
    "Xtrain, Xtest, ytrain, ytest = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "elements = df.index.values\n",
    "elementtrain = elements[:int(0.8*len(elements))]\n",
    "elementtest = elements[int(0.8*len(elements)):]\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMEOdJEzVGSC"
   },
   "source": [
    "\n",
    "The trained model will predict the SFE using orginal independent variables, and the output is named `ytrain_pred`. The graph is shown, and the RSS value calculated to determine whether the model is is effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "9f_IAG5Eeo7P",
    "outputId": "a52ded07-b3ca-43a4-defc-1080cd60d802"
   },
   "outputs": [],
   "source": [
    "ytrain_pred = regr.predict(Xtrain)\n",
    "plt.plot(elementtrain, ytrain_pred, 'o')\n",
    "plt.plot(elementtrain, ytrain, 'o')\n",
    "\n",
    "plt.xlabel(\"Element\")\n",
    "plt.ylabel(\"SFE\")\n",
    "plt.legend([\"Predicted\", \"Actual\"], bbox_to_anchor=(1, 0.9), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dq50Ocbseo7P",
    "outputId": "3de5ade9-beeb-409f-ae33-ab35be4a3529"
   },
   "outputs": [],
   "source": [
    "RSS_train = np.mean((ytrain_pred-ytrain)**2)/(np.std(ytrain)**2)\n",
    "RSS_train\n",
    "# RSS_train = np.sum((ytrain_pred-ytrain)**2)/np.sum((ytrain-np.mean(ytrain))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBnVQXVKW3r-"
   },
   "source": [
    "### Linear Model Testing\n",
    "The testing procedure follows the training procedure, except we are using `Xtest` and `ytest`. These data sets remain untouched by the model, allowing us to measure the actual performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "VL1p2SmNeo7P",
    "outputId": "d112da64-0796-4c7a-b830-2a6cbbd2e0c8"
   },
   "outputs": [],
   "source": [
    "ytest_pred = regr.predict(Xtest)\n",
    "plt.plot(elementtest, ytest_pred, 'o')\n",
    "plt.plot(elementtest, ytest, 'o')\n",
    "\n",
    "plt.xlabel(\"Element\")\n",
    "plt.ylabel(\"SFE\")\n",
    "plt.legend([\"Predicted\", \"Actual\"], bbox_to_anchor=(1, 0.9), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPo-5riWeo7P"
   },
   "source": [
    "### Results\n",
    "\n",
    "Measure the normalized RSS on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Es9wm4hjeo7P",
    "outputId": "a7de1ddb-a511-4b15-8a30-57a3ecbbbe83"
   },
   "outputs": [],
   "source": [
    "RSS_test = np.sum((ytest_pred-ytest)**2)/np.sum((ytest-np.mean(ytest))**2)\n",
    "RSS_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHVepN_jcIaT"
   },
   "source": [
    "# Quantum Model Testing\n",
    "Source: [Qiskit Machine Learning 0.7.2](https://qiskit-community.github.io/qiskit-machine-learning/tutorials/02_neural_network_classifier_and_regressor.html#Regression)\n",
    "\n",
    "## Quantum Support Vector Regressor (QSVR)\n",
    "I first tried QSVR, as it is easier to set up.\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcJxYstfQ_zf",
    "outputId": "a2c69da0-ceae-45a8-d2b1-0716935f3d8b"
   },
   "outputs": [],
   "source": [
    "###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from qiskit_aer import Aer\n",
    "from qiskit.circuit.library import PauliFeatureMap, RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.algorithms import VQR\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "from qiskit_machine_learning.algorithms import QSVR\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "# service = QiskitRuntimeService(channel=\"ibm_quantum\", token=\"\")\n",
    "# backend = service.least_busy(operational=True, simulator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"qml_training-validation-data.csv\")\n",
    "X = df[['Element', 'el_neg', 'B/GPa', 'Volume/A^3']].values\n",
    "y = df['SFE/mJm^-3'].values\n",
    "\n",
    "test_ratio = 0.1\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaler = StandardScaler()\n",
    "y_train_scaler = StandardScaler()\n",
    "X_test_scaler = StandardScaler()\n",
    "y_test_scaler = StandardScaler()\n",
    "\n",
    "def prepare_dataset():\n",
    "    y_scaled = y_scaler.fit_transform(y.reshape(-1,1))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_scaled, test_size=test_ratio, shuffle=True)\n",
    "    y_test_copy = y_test\n",
    "    \n",
    "    X_joined = np.concatenate((X_train[:,1:], X_test[:,1:]))\n",
    "    X_joined = X_scaler.fit_transform(X_joined.reshape(-1,3))\n",
    "\n",
    "    element_test = X_test[:,0]\n",
    "    \n",
    "    X_train = X_joined[:int(len(X_joined)*0.9)]\n",
    "    X_test = X_joined[int(len(X_joined)*0.9):]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, element_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = ZZFeatureMap(feature_dimension=3, reps=5)  # Adjust feature_dimension as needed\n",
    "kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "\n",
    "def reconfig_feature_map(reps):\n",
    "    feature_map = ZZFeatureMap(feature_dimension=3, reps=reps)\n",
    "    kernel = FidelityQuantumKernel(feature_map=feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quantum kernel\n",
    "qsvr = QSVR(C=20.0, epsilon=0.2, quantum_kernel=kernel)\n",
    "def reconfig_quantum_kernel(C):\n",
    "    qsvr = QSVR(C=20.0, epsilon=0.2, quantum_kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    qsvr.fit(X_train, y_train)\n",
    "    y_hat = qsvr.predict(X_test)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9eIlz4D3SUmz",
    "outputId": "5f3a98fb-7e13-4055-965a-916aefb888ea"
   },
   "outputs": [],
   "source": [
    "def graph(y_hat, y_test, message):\n",
    "    y_hat = y_scaler.inverse_transform(y_hat.reshape(-1,1))\n",
    "    y_test = y_scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "    plt.plot(elementtest, y_hat, 'o')\n",
    "    plt.plot(elementtest, y_test, 'o')\n",
    "    \n",
    "    plt.xlabel(\"Element\")\n",
    "    plt.ylabel(\"SFE\")\n",
    "    plt.legend([\"Predicted\", \"Actual\"], bbox_to_anchor=(1, 0.9), loc='upper left')\n",
    "    plt.savefig(message,dpi=300)\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "    return y_test, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_hat):\n",
    "    return r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reps = 1\n",
    "reps_end = 11\n",
    "C = 1\n",
    "C_end = 21\n",
    "iter = 30\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "template = \"QSVR/zz/QVSR_zz_\"\n",
    "df = pd.DataFrame(columns=['reps', 'C', 'i', 'r^2'])\n",
    "\n",
    "for j in range(C, C_end): # C\n",
    "    for z in range(reps, reps_end):# reps\n",
    "        for i in range(iter):\n",
    "            message = ''\n",
    "            message += template\n",
    "            message += f\"{z}_{j}_i{i}_prediction.png\"\n",
    "            X_train, y_train, X_test, y_test, elementtest = prepare_dataset()\n",
    "            reconfig_feature_map(z)\n",
    "            reconfig_quantum_kernel(j)\n",
    "            y_hat = train(X_train, y_train)\n",
    "            y_test, y_hat = graph(y_hat, y_test, message)\n",
    "            new_row = {'reps': z, 'C': j, 'i': i, 'r^2': accuracy(y_test, y_hat)}\n",
    "            df.loc[len(df)] = new_row\n",
    "\n",
    "df.to_csv('QSVR/zz/result/data.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EstimatorQNN (NOT TESTED AND NEEDS FIX)\n",
    "\n",
    "The second attempt uses EstimatorQNN to perform a regression. EstimatorQNN evaluates quantum mechanical observables (some quantum state that can be obtained by a sequence of operatorion. Source: Wikipedia). We will also construct a QNNCircuit, which involves input parameters and an ansatz.\n",
    "\n",
    "Source: https://qiskit-community.github.io/qiskit-machine-learning/tutorials/02_neural_network_classifier_and_regressor.html\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_algorithms.optimizers import COBYLA, L_BFGS_B\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "from qiskit_machine_learning.algorithms.regressors import NeuralNetworkRegressor, VQR\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "\n",
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"qml_training-validation-data.csv\")\n",
    "X = df[['Element', 'el_neg', 'B/GPa', 'Volume/A^3']].values\n",
    "y = df['SFE/mJm^-3'].values\n",
    "\n",
    "elementtest = X_test[:,0]\n",
    "X = MinMaxScaler().fit_transform(X[:,1:])\n",
    "# y = MinMaxScaler().fit_transform(y.reshape(-1,1))\n",
    "# print(X)\n",
    "\n",
    "test_ratio = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=True)\n",
    "elementtest = X_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with EstimatorQNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the feature map\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "\n",
    "num_qubits = 3\n",
    "\n",
    "# Construct the ansatz\n",
    "param_y = Parameter(\"y\")\n",
    "ansatz = QuantumCircuit(num_qubits, name=\"vf\")\n",
    "for i in range(num_qubits):\n",
    "    ansatz.ry(param_y, i)\n",
    "\n",
    "# Construct the circuit\n",
    "qc = QNNCircuit(feature_map=ZZFeatureMap(num_qubits,reps=1), ansatz=ansatz)\n",
    "\n",
    "\n",
    "# construct QNN\n",
    "regression_estimator_qnn = EstimatorQNN(circuit=qc)\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = NeuralNetworkRegressor(\n",
    "    neural_network=regression_estimator_qnn,\n",
    "    loss=\"squared_error\",\n",
    "    optimizer=L_BFGS_B(maxiter=5),\n",
    "    callback=callback_graph,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# fit to data\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# return to default figsize\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "\n",
    "# score the result\n",
    "regressor.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regressor.predict(X_test)\n",
    "print(y_hat)\n",
    "\n",
    "plt.plot(elementtest, y_hat, 'o')\n",
    "plt.plot(elementtest, y_test, 'o')\n",
    "\n",
    "plt.xlabel(\"Element\")\n",
    "plt.ylabel(\"SFE\")\n",
    "plt.legend([\"Predicted\", \"Actual\"], bbox_to_anchor=(1, 0.9), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Quantum Regressor (VQR)\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "from qiskit_machine_learning.algorithms.regressors import VQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"qml_training-validation-data.csv\")\n",
    "X = df[['Element', 'el_neg', 'B/GPa', 'Volume/A^3']].values\n",
    "y = df['SFE/mJm^-3'].values\n",
    "\n",
    "test_ratio = 0.1\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaler = StandardScaler()\n",
    "y_train_scaler = StandardScaler()\n",
    "X_test_scaler = StandardScaler()\n",
    "y_test_scaler = StandardScaler()\n",
    "\n",
    "def prepare_dataset(X, y, X_scaler, y_scaler, test_ratio):\n",
    "    y = y_scaler.fit_transform(y.reshape(-1,1))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=True)\n",
    "    y_test_copy = y_test\n",
    "    \n",
    "    X_joined = np.concatenate((X_train[:,1:], X_test[:,1:]))\n",
    "    X_joined = X_scaler.fit_transform(X_joined.reshape(-1,3))\n",
    "\n",
    "    element_test = X_test[:,0]\n",
    "    \n",
    "    X_train = X_joined[:int(len(X_joined)*0.9)]\n",
    "    X_test = X_joined[int(len(X_joined)*0.9):]\n",
    "    \n",
    "    # X_train = X_train_scaler.fit_transform(X_train[:,1:])\n",
    "    # y_train = y_scaler.fit_transform(y_train.reshape(-1,1))\n",
    "    # y_train = y_train.reshape(-1,1)\n",
    "    \n",
    "    # X_test = X_test_scaler.fit_transform(X_test[:,1:])\n",
    "    # y_test = y_scaler.fit_transform(y_test.reshape(-1,1))\n",
    "    # y_test = y_test.reshape(-1,1)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, element_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = PauliFeatureMap(feature_dimension=3, reps=2, entanglement='full', alpha=1.0)\n",
    "def reconfig_featureMap(alpha):\n",
    "    feature_map = PauliFeatureMap(feature_dimension=3, reps=2, entanglement='full', alpha=alpha)\n",
    "feature_map.decompose().draw(output=\"mpl\", style=\"clifford\", fold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = RealAmplitudes(num_qubits=3, reps=3)\n",
    "ansatz.decompose().draw(output=\"mpl\", style=\"clifford\", fold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = COBYLA(maxiter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function and Callback Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, message):\n",
    "    vqr = VQR(\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz,\n",
    "        optimizer=optimizer,\n",
    "        callback=callback_graph,\n",
    "    )\n",
    "    \n",
    "    # clear objective value history\n",
    "    objective_func_vals = []\n",
    "    \n",
    "    start = time.time()\n",
    "    vqr.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # plt.savefig(Path(message+\"train.png\"),dpi=300) # not gonna work\n",
    "    \n",
    "    print(f\"Training time: {round(elapsed)} seconds\")\n",
    "    return vqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_result(vqr, X_train, y_train):\n",
    "    train_score = vqr.score(X_train, y_train)\n",
    "    return train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction_graph(vqr, element_test, y_test, message):\n",
    "    # y_hat = vqr.predict(X_test_scaler.inverse_transform(X_test))\n",
    "    y_hat = vqr.predict(X_test)\n",
    "    y_test = y_scaler.inverse_transform(y_test)\n",
    "    y_hat = y_scaler.inverse_transform(y_hat)\n",
    "    plt.plot(element_test, y_scaler.inverse_transform(y_hat), 'o')\n",
    "    plt.plot(element_test, y_scaler.inverse_transform(y_test), 'o')\n",
    "    \n",
    "    plt.xlabel(\"Element\")\n",
    "    plt.ylabel(\"SFE\")\n",
    "    plt.legend([\"Predicted\", \"Actual\"], bbox_to_anchor=(1, 0.9), loc='upper left')\n",
    "\n",
    "    plt.savefig(Path(message+\"prediction.png\"),dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    return y_test, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_hat):\n",
    "    return r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter = 30\n",
    "\n",
    "# edit this\n",
    "template = \"VQR/pauli/VQR_pauli_j_ii_\"\n",
    "# ! mkdir VQR/pauli\n",
    "start = 1\n",
    "end = 2\n",
    "step = 0.1\n",
    "with open('VQR/pauli/accuracy.csv', mode='w', newline='') as file: \n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    for j in range(int((end-start)/step)+1):\n",
    "        pairs = []\n",
    "        for i in range(iter):\n",
    "            reconfig_featureMap(start)\n",
    "            message = template[:20] + str(round(start,1)) + template[21:23] + str(i) + template[24:] # modify the output figure name\n",
    "            X_train, y_train, X_test, y_test, element_test = prepare_dataset(X, y, X_scaler, y_scaler, test_ratio)\n",
    "            vqr = train(X_train, y_train, message)\n",
    "            y_test, y_hat = show_prediction_graph(vqr, element_test, y_test, message)\n",
    "            \n",
    "            pair = (y_test, y_hat)\n",
    "            pairs.append(pair)\n",
    "            \n",
    "        r2_values = [r2_score(pair[0], pair[1]) for pair in pairs]\n",
    "\n",
    "        writer.writerow(r2_values)\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.boxplot(data=r2_values)\n",
    "        plt.title(\"Whisker Plot for R^2 Values\")\n",
    "        plt.ylabel(\"R^2\")\n",
    "        plt.savefig(f\"VQR/pauli/VQR_pauli_{round(start,1)}_r2.png\",dpi=300)\n",
    "            \n",
    "        start += step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different feature map\n",
    "# scaling\n",
    "# Entanglement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
